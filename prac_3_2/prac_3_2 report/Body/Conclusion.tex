\section{Conclusion}

The experiments show tha that small matrix sizes, single-threaded matrix multiplication is faster due to over heads.
As the matrix size increases, parallelized multiplication becomes quicker due to overhead becoming negligible relative to computation time.
The overhead includes OpenCL setup overheads and kernel startup overheads, with the former being constant and the latter increasing linearly with matrix count.
Due to the kernel startup overheads , parallelization efficiency improves slightly with larger matrix counts.
Overall, parallelized multiplication offers significant speedup for larger matrices compared to the single-threaded approach.